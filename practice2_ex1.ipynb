{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f95a74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085557cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a69796",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m test_size = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.15\u001b[39m * \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[32m     28\u001b[39m val_size = \u001b[38;5;28mlen\u001b[39m(dataset) - train_size - test_size\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m train_data, val_data, test_data = \u001b[43mrandom_split\u001b[49m(dataset, [train_size, val_size, test_size])\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# G√°n transform test cho val v√† test\u001b[39;00m\n\u001b[32m     33\u001b[39m val_data.dataset.transform = test_transform\n",
      "\u001b[31mNameError\u001b[39m: name 'random_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Th∆∞ m·ª•c ch·ª©a dataset\n",
    "data_dir = r\"C:\\Users\\Nguyen Trung An\\Downloads\\DL_Practice-dong (1)\\DL_Practice-dong\\practice2\\flowers\"\n",
    "\n",
    "# Chu·∫©n h√≥a theo ImageNet\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.299, 0.224, 0.225)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# T·∫°o dataset ch√≠nh\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n",
    "\n",
    "# Chia th√†nh train / val / test\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = int(0.15 * len(dataset))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# G√°n transform test cho val v√† test\n",
    "val_data.dataset.transform = test_transform\n",
    "test_data.dataset.transform = test_transform\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ Dataloader created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"T·ªïng s·ªë ·∫£nh trong dataset: {len(dataset)}\")\n",
    "print(f\"C√°c l·ªõp: {dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48010573",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nüîπ Epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0.0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    train_acc = train_correct / len(train_loader.dataset)\n",
    "    val_acc = val_correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor board\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/flower_exp_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8181958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch, writer, device):\n",
    "    model.train()\n",
    "    running_loss, running_correct = 0.0, 0\n",
    "    total_samples = len(dataloader.dataset)\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Training]\", leave=False)\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(progress_bar):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # C·∫≠p nh·∫≠t th·ªëng k√™\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "        running_correct += (preds == y).sum().item()\n",
    "\n",
    "        # Log t·ª´ng batch\n",
    "        global_step = epoch * len(dataloader) + batch_idx\n",
    "        batch_acc = 100.0 * (preds == y).sum().item() / X.size(0)\n",
    "        writer.add_scalar(\"Train/Loss_batch\", loss.item(), global_step)\n",
    "        writer.add_scalar(\"Train/Acc_batch\", batch_acc, global_step)\n",
    "\n",
    "        # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh\n",
    "        progress_bar.set_postfix(loss=loss.item(), acc=batch_acc)\n",
    "\n",
    "    # T√≠nh k·∫øt qu·∫£ epoch\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = 100.0 * running_correct / total_samples\n",
    "\n",
    "    # Log trung b√¨nh epoch\n",
    "    writer.add_scalar(\"Train/Loss_epoch\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Acc_epoch\", epoch_acc, epoch)\n",
    "\n",
    "    # Log histogram tr·ªçng s·ªë (ƒë·ªÉ xem s·ª± thay ƒë·ªïi tham s·ªë)\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            writer.add_histogram(f\"Weights/{name}\", param.detach().cpu(), epoch)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# -------------------------------\n",
    "# üîπ Validation Loop\n",
    "# -------------------------------\n",
    "def val_loop(dataloader, model, loss_fn, epoch, writer, device):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0.0, 0\n",
    "    total_samples = len(dataloader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=f\"Validation Epoch {epoch+1}\", leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            val_loss += loss_fn(outputs, y).item() * X.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "\n",
    "    # Trung b√¨nh loss & t√≠nh ƒë·ªô ch√≠nh x√°c\n",
    "    val_loss /= total_samples\n",
    "    val_acc = 100.0 * correct / total_samples\n",
    "\n",
    "    # Ghi log TensorBoard\n",
    "    writer.add_scalar(\"Val/Loss_epoch\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Val/Accuracy_epoch\", val_acc, epoch)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4cd318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, writer, device):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0.0, 0\n",
    "    total_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=\"Testing\", leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            test_loss += loss_fn(outputs, y).item()\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_acc = 100.0 * correct / total_samples\n",
    "\n",
    "    print(f\"\\nüìä Test Results:\\n Accuracy: {test_acc:.2f}% | Avg Loss: {test_loss:.6f}\")\n",
    "\n",
    "    # Log TensorBoard\n",
    "    writer.add_scalar(\"Test/Loss\", test_loss)\n",
    "    writer.add_scalar(\"Test/Accuracy\", test_acc)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b414841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "# Kh·ªüi t·∫°o TensorBoard writer\n",
    "writer = SummaryWriter('runs/flower_classifier')\n",
    "\n",
    "EPOCHS = 10\n",
    "best_val_acc = 0.0\n",
    "best_model_path = \"best_flower_classifier.pth\"\n",
    "\n",
    "print(\"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh ResNet18 tr√™n t·∫≠p d·ªØ li·ªáu hoa...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"üå∏ Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "    # üîπ Hu·∫•n luy·ªán (truy·ªÅn th√™m device)\n",
    "    train_loss, train_acc = train_loop(train_loader, model, loss_fn, optimizer, epoch, writer, device)\n",
    "\n",
    "    # üîπ ƒê√°nh gi√° (validation)\n",
    "    val_loss, val_acc = val_loop(val_loader, model, loss_fn, epoch, writer, device)\n",
    "\n",
    "    # In k·∫øt qu·∫£ Epoch\n",
    "    print(f\"üìò Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"üìó Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # L∆∞u model n·∫øu t·ªët h∆°n\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"‚úÖ Model improved! Saved new best model (Val Acc = {val_acc:.2f}%)\")\n",
    "\n",
    "    print()\n",
    "\n",
    "writer.close()\n",
    "print(f\"üéâ Training complete! Best model saved at '{best_model_path}' with Val Acc = {best_val_acc:.2f}%\")\n",
    "\n",
    "# ===================================================\n",
    "# üîπ ƒê√°nh gi√° m√¥ h√¨nh t·ªët nh·∫•t tr√™n t·∫≠p test\n",
    "# ===================================================\n",
    "print(\"\\nüîç Loading best model for final evaluation...\")\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "test_loss, test_acc = test_loop(test_loader, model, loss_fn, writer, device)\n",
    "print(f\"üèÅ Final Test Accuracy: {test_acc:.2f}% | Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "print(\"\\nüîç Evaluating on test set...\")\n",
    "test_loss, test_acc = test_loop(test_loader, model, loss_fn, writer, device)\n",
    "print(f\"üèÅ Final Test Accuracy: {test_acc:.2f}% | Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_flower_classifier.pth\", map_location=device))\n",
    "model.to(device)\n",
    "print(\"‚úÖ Best model loaded successfully!\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nüîç Evaluating on test set...\")\n",
    "test_loss, test_acc = test_loop(test_loader, model, loss_fn, writer, device)\n",
    "print(f\"üèÅ Final Test Accuracy: {test_acc:.2f}% | Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ===== Load dataset ƒë·ªÉ l·∫•y class names =====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = dataset = datasets.ImageFolder(\n",
    "    root=r\"C:\\Users\\Nguyen Trung An\\Downloads\\DL_Practice-dong (1)\\DL_Practice-dong\\practice2\\flowers\",\n",
    "    transform=train_transforms\n",
    ")\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# ===== H√†m hi·ªÉn th·ªã ·∫£nh =====\n",
    "def imshow(img, ax):\n",
    "    img = img.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean  # unnormalize\n",
    "    img = np.clip(img, 0, 1)\n",
    "    ax.imshow(img)\n",
    "\n",
    "# ===== Random 10 ·∫£nh t·ª´ test dataset =====\n",
    "test_dataset = test_loader.dataset\n",
    "indices = np.random.choice(len(test_dataset), size=10, replace=False)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for idx in indices:\n",
    "    img, label = test_dataset[idx]\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "images = torch.stack(images).to(device)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# ===== D·ª± ƒëo√°n =====\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "# ===== Hi·ªÉn th·ªã ·∫£nh v√† k·∫øt qu·∫£ =====\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "for i in range(10):\n",
    "    ax = axes[i]\n",
    "    imshow(images[i], ax)\n",
    "    true_label = class_names[labels[i].item()]\n",
    "    pred_label = class_names[preds[i].item()]\n",
    "    color = \"green\" if true_label == pred_label else \"red\"\n",
    "    ax.set_title(f\"Pred: {pred_label}\\nTrue: {true_label}\", color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
