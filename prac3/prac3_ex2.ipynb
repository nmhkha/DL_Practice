{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fde5d1f",
   "metadata": {},
   "source": [
    "# Exercise 2: Finetuning a Pretrained Model for Binary Text Classification\n",
    "Tên : Nguyễn Văn Thương\n",
    "\n",
    "Mssv : 077205005581"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd3613",
   "metadata": {},
   "source": [
    "# Load dataset (Yelp Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac479ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load yelp_review_full as in the docs\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "print(dataset)\n",
    "# dataset has 'train' and 'test' splits and a 'text' and 'label' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10725212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 1, 'text': \"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\"}\n"
     ]
    }
   ],
   "source": [
    "def to_binary(example):\n",
    "    # original labels: 0..4 (5 classes) for yelp_review_full\n",
    "    # map: 0,1 -> 0 (negative); 2,3,4 -> 1 (positive)\n",
    "    orig = example[\"label\"]\n",
    "    return {\"label\": 0 if orig <= 1 else 1}\n",
    "\n",
    "dataset = dataset.map(to_binary)\n",
    "# kiểm tra\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9e2d7",
   "metadata": {},
   "source": [
    "# Load pretrained model và tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6686427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"google-bert/bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "# thông báo: classifier.* mới được khởi tạo lại — cần fine-tune. (This is expected.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248fcaaf",
   "metadata": {},
   "source": [
    "# Preprocess dataset (tokenize, pad, truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88b14529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# map tokenizer\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# optional: select small subsets for quick testing (khuyên bởi docs)\n",
    "small_train = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "# If you want to train on full: use tokenized_datasets[\"train\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350981cc",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "852a37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"yelp_binary_classifier\",\n",
    "    eval_strategy=\"epoch\",  # evaluate at end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    push_to_hub=False,  # set True if you want to push to HF Hub and have logged in\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556a9b1",
   "metadata": {},
   "source": [
    "# Tạo Trainer và finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import Trainer\n",
    "\n",
    "# load accuracy metric (as docs)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# tạo trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train,  # or tokenized_datasets[\"train\"] for full\n",
    "    eval_dataset=small_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d722501",
   "metadata": {},
   "source": [
    "# Evaluate the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25986f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on eval dataset\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_results)\n",
    "\n",
    "# optional: make predictions on new sentences\n",
    "predict_texts = [\n",
    "    \"The food was awful and service was terrible.\",\n",
    "    \"Excellent place! I loved the pizza and the staff were very friendly.\"\n",
    "]\n",
    "# tokenize inputs\n",
    "encodings = tokenizer(predict_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# use trainer.predict to get logits then map to labels\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10)))\n",
    "# or simpler: use trainer.predict on new dataset wrapped as Dataset object\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
